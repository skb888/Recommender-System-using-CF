{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read Data From CSV file\n",
    "import pandas as pd\n",
    "df=pd.read_csv('NEWDATATABLE.csv', sep=',',header=None)\n",
    "ratings = df.values\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_generation(ratings):\n",
    "    #Cretae train and test matrix\n",
    "    test = np.ones(ratings.shape) * 99 #24983*100 and initzalize all be unknown 99 and ratings.shape[0] return 24983\n",
    "    train = ratings.copy()\n",
    "    #Make all unknown numbers 99 be 0\n",
    "    train = train - np.ones(ratings.shape) * 99\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        #Randomly pick 10 ratings from each user to be in test case (include unknown ratings)\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size = 20, replace = False)\n",
    "        #Set chosen be zero in training\n",
    "        train [user, test_ratings] = 0.\n",
    "        #Assign chosen rating to test case\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "    train = train + np.ones(ratings.shape) * 99\n",
    "    #Make sure train and test are disjoint \n",
    "    #assert(np.all((train * test) == 0))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the function and then assign train and test\n",
    "train, test = train_test_generation(ratings)\n",
    "trainMAE = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find averge of each column\n",
    "train_average_column = np.zeros(100)\n",
    "for indexI in range(100):\n",
    "    tempsum = 0\n",
    "    count = 0\n",
    "    for indexJ in range(24983):\n",
    "        if train[indexJ][indexI] != 99:\n",
    "            tempsum = tempsum + train[indexJ][indexI]\n",
    "            count = count + 1\n",
    "    train_average_column[indexI] = float(tempsum) / count\n",
    "#Find averge of each row\n",
    "train_average_row = np.zeros(24983)\n",
    "for indexI in range(24983):\n",
    "    tempsum = 0;\n",
    "    count = 0; \n",
    "    for indexJ in range(100):\n",
    "        if train[indexI][indexJ] != 99:\n",
    "            tempsum = tempsum + train[indexI][indexJ]\n",
    "            count = count + 1\n",
    "    train_average_row[indexI] = float(tempsum) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_norm is used for svd and train is used for CF item/user based\n",
    "train_norm = train.copy()\n",
    "#Fill the sparse with avergae of item score\n",
    "for indexI in range(24983):\n",
    "    for indexJ in range(100):\n",
    "        if train_norm[indexI][indexJ] == 99:\n",
    "            train_norm[indexI][indexJ] = train_average_column[indexJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Substraction of customer AVG from each rating\n",
    "for indexI in range(24983):\n",
    "    for indexJ in range(100):\n",
    "        train_norm[indexI][indexJ] = train_norm[indexI][indexJ] - train_average_row[indexI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_absolute_error\n",
    "#Compute MAE in training and test\n",
    "def get_mae(pred, actual):\n",
    "    mae_sum = 0\n",
    "    count = 0\n",
    "    for indexI in range(24983):\n",
    "        for indexJ in range(100):\n",
    "            if actual[indexI][indexJ] != 99:\n",
    "                mae_sum = mae_sum + np.abs(pred[indexI][indexJ] - actual[indexI][indexJ])\n",
    "                count = count + 1    \n",
    "    mae_sum = float(mae_sum) / count\n",
    "    return mae_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD training MAE: 2.8567441853\n",
      "SVD testing MAE: 3.28782178729\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "U, sigma, Vt = svds(train_norm, k=10)\n",
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + train_average_row.reshape(-1,1)\n",
    "\n",
    "print 'SVD training MAE: ' + str(get_mae(all_user_predicted_ratings, train))\n",
    "print 'SVD testing MAE: ' + str(get_mae(all_user_predicted_ratings, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basis = 60\n",
    "train_first_half = train[:,0:basis]\n",
    "train_second_half = train[:,basis:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute train_first_half\n",
    "#Find averge of each column \n",
    "train_average_column_first_half = np.zeros(basis)\n",
    "for indexI in range(basis):\n",
    "    tempsum = 0\n",
    "    count = 0\n",
    "    for indexJ in range(len(train_first_half)):\n",
    "        if train_first_half[indexJ][indexI] != 99:\n",
    "            tempsum = tempsum + train_first_half[indexJ][indexI]\n",
    "            count = count + 1\n",
    "    if count != 0:\n",
    "        train_average_column_first_half[indexI] = float(tempsum) / count\n",
    "    else:\n",
    "        break\n",
    "#Find averge of each row\n",
    "train_average_row_first_half = np.zeros(len(train_first_half))\n",
    "for indexI in range(len(train_first_half)):\n",
    "    tempsum = 0;\n",
    "    count = 0; \n",
    "    for indexJ in range(basis):\n",
    "        if train_first_half[indexI][indexJ] != 99:\n",
    "            tempsum = tempsum + train_first_half[indexI][indexJ]\n",
    "            count = count + 1\n",
    "    if count != 0:\n",
    "        train_average_row_first_half[indexI] = float(tempsum) / count\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_norm is used for svd and train is used for CF item/user based\n",
    "train_norm_first_half = train_first_half.copy()\n",
    "#Fill the sparse with avergae of item score\n",
    "for indexI in range(len(train_first_half)):\n",
    "    for indexJ in range(basis):\n",
    "        if train_norm_first_half[indexI][indexJ] == 99:\n",
    "            train_norm_first_half[indexI][indexJ] = train_average_column_first_half[indexJ]\n",
    "\n",
    "#Substraction of customer AVG from each rating\n",
    "for indexI in range(len(train_first_half)):\n",
    "    for indexJ in range(basis):\n",
    "        train_norm_first_half[indexI][indexJ] = train_norm_first_half[indexI][indexJ] - train_average_row_first_half[indexI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute train_second_half\n",
    "#Find averge of each column \n",
    "train_average_column_second_half = np.zeros(100-basis)\n",
    "for indexI in range(100-basis):\n",
    "    tempsum = 0\n",
    "    count = 0\n",
    "    for indexJ in range(len(train_second_half)):\n",
    "        if train_second_half[indexJ][indexI] != 99:\n",
    "            tempsum = tempsum + train_second_half[indexJ][indexI]\n",
    "            count = count + 1\n",
    "    if count != 0:\n",
    "        train_average_column_second_half[indexI] = float(tempsum) / count\n",
    "    else:\n",
    "        break\n",
    "#Find averge of each row\n",
    "train_average_row_second_half = np.zeros(len(train_second_half))\n",
    "for indexI in range(len(train_second_half)):\n",
    "    tempsum = 0;\n",
    "    count = 0; \n",
    "    for indexJ in range(100-basis):\n",
    "        if train_second_half[indexI][indexJ] != 99:\n",
    "            tempsum = tempsum + train_second_half[indexI][indexJ]\n",
    "            count = count + 1\n",
    "    if count != 0:\n",
    "        train_average_row_second_half[indexI] = float(tempsum) / count\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_norm is used for svd and train is used for CF item/user based\n",
    "train_norm_second_half = train_second_half.copy()\n",
    "#Fill the sparse with avergae of item score\n",
    "for indexI in range(len(train_second_half)):\n",
    "    for indexJ in range(100-basis):\n",
    "        if train_norm_second_half[indexI][indexJ] == 99:\n",
    "            train_norm_second_half[indexI][indexJ] = train_average_column_second_half[indexJ]\n",
    "\n",
    "#Substraction of customer AVG from each rating\n",
    "for indexI in range(len(train_second_half)):\n",
    "    for indexJ in range(100-basis):\n",
    "        train_norm_second_half[indexI][indexJ] = train_norm_second_half[indexI][indexJ] - train_average_row_second_half[indexI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute based SVD\n",
    "U, sigma, Vt = svds(train_norm_first_half, k=10)\n",
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute to find projection of terms on to span of current documents\n",
    "from numpy.linalg import inv\n",
    "sigma_inv = inv(sigma)\n",
    "d_hut = np.dot(np.dot(train_norm_second_half.T,U),sigma_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = np.concatenate((Vt, d_hut.T), axis=1)\n",
    "all_user_predicted_ratings_final = np.dot(np.dot(U, sigma), combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_avg = train_average_row\n",
    "all_user_predicted_ratings_final_withavg = all_user_predicted_ratings_final + combined_avg.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD training MAE: 2.92424312306\n",
      "SVD testing MAE: 3.38386505253\n"
     ]
    }
   ],
   "source": [
    "print 'SVD training MAE: ' + str(get_mae(all_user_predicted_ratings_final_withavg, train))\n",
    "print 'SVD testing MAE: ' + str(get_mae(all_user_predicted_ratings_final_withavg, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
