# Recommender-System-using-CF

This report presents three different experiments where I have explored one technology called collaborative filtering. The first experiment compares the quality of a recommender system using Baseline Model, Pure SVD, Stochastic Gradient Descend (SGD), Alternating Least Squares (ALS), Item-based Similarity, and Userbased Similarity. I compared the effectiveness of recommender systems at predicting ratings in the both training sets and testing sets. The evaluation metric of the rating prediction is Mean Absolute Error (MAE) because it is most commonly used and easiest to interpret. The second experiment compares the quality of different recommender systems at producing Top-N items. The evaluation of judging Top-N items is using standard F1 metric, which is based on computing recall and precision. The first part of comparing the effectiveness of Top-N items is using Pure SVD in high dimension and low dimension. The second part is to compare the effectiveness under Pure SVD, Stochastic Gradient Descend (SGD), Alternating Least Squares (ALS), Item-based Similarity, and User-based Similarity. The third experiment is to evaluate theperformance of on-line system and off-line version. The Incremental SVD algorithm is applied to update SVD because folding-in just relies on the existing latent semantic structure. Meanwhile, the evaluation metric of the performance is still Mean Absolute Error (MAE), which is based on different training and test ratio and folding-in model size. My experiments suggest that SVD has the potential to meet different challenges of recommender system at making both rating predictions and recommending Top-N items. SVD based models can also make the recommender system highly scalable and less cost in some degree.
