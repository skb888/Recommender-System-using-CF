{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read Data From CSV file\n",
    "import pandas as pd\n",
    "df=pd.read_csv('NEWDATATABLE.csv', sep=',',header=None)\n",
    "ratings = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 10 known to be in test case\n",
    "def train_test_generation(ratings):\n",
    "    #Cretae train and test matrix\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        temp = list(ratings[user, :])\n",
    "        temp_list = []\n",
    "        count = 0\n",
    "        # Choose top 10 known to be in test case\n",
    "        for item in temp:\n",
    "            if item != 99:\n",
    "                temp_list.append(item)\n",
    "        temp_list = sorted(temp_list, reverse=True)  \n",
    "        while count < 10:\n",
    "            count = count + 1\n",
    "            Index_temp = temp.index(temp_list[count])\n",
    "            #Set chosen be zero in training\n",
    "            train [user, Index_temp] = 0.\n",
    "            #Assign chosen rating to test case\n",
    "            test[user, Index_temp] = ratings[user, Index_temp]\n",
    "            ratings[user, Index_temp] = 0.\n",
    "            temp = list(ratings[user, :])\n",
    "            temp_list = []\n",
    "            for item in temp:\n",
    "                if item != 99:\n",
    "                    temp_list.append(item)\n",
    "            temp_list = sorted(temp_list, reverse=True)  \n",
    "              \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call the function and then assign train and test\n",
    "train, test = train_test_generation(ratings)\n",
    "trainMAE = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find averge of each column\n",
    "train_average_column = np.zeros(100)\n",
    "for indexI in range(100):\n",
    "    tempsum = 0;\n",
    "    count = 0; \n",
    "    for indexJ in range(24983):\n",
    "        if train[indexJ][indexI] != 99:\n",
    "            tempsum = tempsum + train[indexJ][indexI]\n",
    "            count = count + 1\n",
    "    train_average_column[indexI] = float(tempsum) / count\n",
    "#Find averge of each row\n",
    "train_average_row = np.zeros(24983)\n",
    "for indexI in range(24983):\n",
    "    tempsum = 0;\n",
    "    count = 0; \n",
    "    for indexJ in range(100):\n",
    "        if train[indexI][indexJ] != 99:\n",
    "            tempsum = tempsum + train[indexI][indexJ]\n",
    "            count = count + 1\n",
    "    train_average_row[indexI] = float(tempsum) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_norm is used for svd and train is used for CF item/user based\n",
    "train_norm = train.copy()\n",
    "#Fill the sparse with avergae of item score\n",
    "for indexI in range(24983):\n",
    "    for indexJ in range(100):\n",
    "        if train_norm[indexI][indexJ] == 99:\n",
    "            train_norm[indexI][indexJ] = train_average_column[indexJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Substraction of customer AVG from each rating\n",
    "for indexI in range(24983):\n",
    "    for indexJ in range(100):\n",
    "        train_norm[indexI][indexJ] = train_norm[indexI][indexJ] - train_average_row[indexI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "U, sigma, Vt = svds(train_norm, k=10)\n",
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + train_average_row.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 30 items for each user in test case and choose Top-N\n",
    "#Pick unkonwn index\n",
    "#evaluate recall and precise\n",
    "unknown_index = []\n",
    "exist_row = []\n",
    "#discard\n",
    "notexist_row = []\n",
    "for indexI in range(24983):\n",
    "    temp_row_index = np.where(train[indexI] == 99)\n",
    "    if len(list(temp_row_index[0])) < 30 :\n",
    "            notexist_row.append(indexI)\n",
    "    else:\n",
    "        temp_row_index_final = list(np.random.choice(temp_row_index[0], size = 30, replace = False))\n",
    "        unknown_index.append(temp_row_index_final)\n",
    "        exist_row.append(indexI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find unknown rating for each user in training\n",
    "from collections import defaultdict\n",
    "combine = zip(exist_row, unknown_index)\n",
    "row_number_result = defaultdict(list)\n",
    "for indexI in range(len(combine)):\n",
    "    row_temp = list()\n",
    "    for item in combine[indexI][1]:\n",
    "        row_temp.append(all_user_predicted_ratings[combine[indexI][0]][item])\n",
    "    row_number_result[combine[indexI][0]].append(row_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort and find median value\n",
    "import math\n",
    "row_median = defaultdict(list)\n",
    "for indexI in range(len(row_number_result)):\n",
    "    b = sorted(row_number_result[combine[indexI][0]][0])\n",
    "    c = b[int(math.floor((len(b))/2))]\n",
    "    d = list()\n",
    "    d.append(c)\n",
    "    row_median[combine[indexI][0]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find known rating for each user in test\n",
    "row_test_result = defaultdict(list)\n",
    "for indexI in range(len(combine)):\n",
    "    a = test[combine[indexI][0]]\n",
    "    a = a[a != 0]\n",
    "    a = list(a)\n",
    "    row_test_result[combine[indexI][0]].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recall_precise(index_matrix, test_index):\n",
    "    recall_result = []\n",
    "    precise_result = []\n",
    "    N = 1\n",
    "    recall_temp = 0\n",
    "    precise_temp = 0\n",
    "    \n",
    "    for item in exist_row:\n",
    "        temp_train_list = index_matrix[item][0]\n",
    "        for item_test in row_test_result[item][0]:\n",
    "            temp_train_list.append(item_test)\n",
    "            temp_sort_list = sorted(temp_train_list, reverse = True)\n",
    "            temp_index = temp_sort_list.index(item_test)\n",
    "            if temp_index < N:\n",
    "                count = 1\n",
    "            else:\n",
    "                count = 0 \n",
    "            recall_temp = count\n",
    "            precise_temp = float(count) / N\n",
    "            recall_result.append(recall_temp)\n",
    "            precise_result.append(precise_temp)\n",
    "    return recall_result, precise_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call two fcns to achieve to find\n",
    "recall_each, precise_each = recall_precise(row_number_result, row_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.296255562684\n",
      "Precise: 0.296255562684\n"
     ]
    }
   ],
   "source": [
    "recall_AVG = float(sum(recall_each)) / len(recall_each)\n",
    "precise_AVG = float(sum(precise_each)) / len(precise_each)\n",
    "print 'Recall: ' + str(recall_AVG)\n",
    "print 'Precise: ' + str(precise_AVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
